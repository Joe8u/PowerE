{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinweis: __file__ nicht verfügbar, SCRIPT_DIR_F1 auf CWD gesetzt: /Users/jonathan/Documents/GitHub/PowerE/scripts/F1_Analyse_Kompensationsforderungen\n",
      "Added project root '/Users/jonathan/Documents/GitHub/PowerE' to sys.path\n",
      "Verwendeter Projekt-Root für dieses Notebook: /Users/jonathan/Documents/GitHub/PowerE\n",
      "FEHLER beim Importieren von Modulen aus 'src': cannot import name 'load_smartplug' from 'src.data_loader.survey_loader.demand_response' (/Users/jonathan/Documents/GitHub/PowerE/src/data_loader/survey_loader/demand_response.py)\n",
      "Bitte stelle sicher, dass der PROJECT_ROOT_NB korrekt ist und alle __init__.py Dateien in src und Unterordnern vorhanden sind.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_smartplug' from 'src.data_loader.survey_loader.demand_response' (/Users/jonathan/Documents/GitHub/PowerE/src/data_loader/survey_loader/demand_response.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEHLER beim Importieren von Modulen aus \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBitte stelle sicher, dass der PROJECT_ROOT_NB korrekt ist und alle __init__.py Dateien in src und Unterordnern vorhanden sind.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEin unerwarteter Fehler beim Importieren ist aufgetreten: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurvey_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdemographics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_demographics\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurvey_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattitudes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_attitudes\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurvey_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdemand_response\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_importance, load_notification, load_smartplug\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurvey_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msocioeconomics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_socioeconomics\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlle benötigten Module aus \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m erfolgreich importiert.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_smartplug' from 'src.data_loader.survey_loader.demand_response' (/Users/jonathan/Documents/GitHub/PowerE/src/data_loader/survey_loader/demand_response.py)"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Masterarbeit: F1 - Analyse der Kompensationsforderungen\n",
    "#\n",
    "# Dieses Notebook dient der Analyse der Umfragedaten zur Beantwortung der ersten Forschungsfrage:\n",
    "# _\"Welche monetären Kompensationsforderungen stellen Haushalte in der Schweiz für die Teilnahme an einem Peak-Shaving-Programm unter Verwendung von Smart-Home-Technologien?\"_\n",
    "#\n",
    "# **Struktur:**\n",
    "# 1. Setup und Laden der Kerndaten (Q9 & Q10 Flexibilitätsdaten)\n",
    "# 2. Laden und Integration weiterer relevanter Umfragedaten (Soziodemografie, Einstellungen)\n",
    "# 3. Analyse der generellen Teilnahmebereitschaft (Q10 `incentive_choice`)\n",
    "# 4. Detaillierte Analyse der monetären Kompensationsforderungen (Q10 `incentive_pct_required`)\n",
    "# 5. Einfluss ausgewählter soziodemografischer Faktoren\n",
    "# 6. (Optional) Einfluss von Geräte-Wichtigkeit (Q8) und DR-Affinität (Q11, Q12)\n",
    "# 7. Zusammenfassung und Export von Ergebnissen\n",
    "\n",
    "# %% [code]\n",
    "# === Abschnitt 1: Setup und Laden der Kerndaten ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# import matplotlib.pyplot as plt # Alternative für manche Plots\n",
    "# import seaborn as sns          # Alternative für manche Plots\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Pfad-Setup ---\n",
    "# Annahme: Das Notebook liegt in PowerE/scripts/F1_Analyse_Kompensationsforderungen/\n",
    "try:\n",
    "    NOTEBOOK_FILE_PATH = Path(__file__).resolve() # Funktioniert, wenn als Skript ausgeführt\n",
    "    SCRIPT_DIR_F1 = NOTEBOOK_FILE_PATH.parent\n",
    "except NameError: # Tritt auf, wenn __file__ nicht definiert ist (typisch für interaktive Notebook-Ausführung)\n",
    "    SCRIPT_DIR_F1 = Path(os.getcwd()).resolve() # Nimmt das aktuelle Arbeitsverzeichnis\n",
    "    print(f\"Hinweis: __file__ nicht verfügbar, SCRIPT_DIR_F1 auf CWD gesetzt: {SCRIPT_DIR_F1}\")\n",
    "\n",
    "# Erwarte, dass SCRIPT_DIR_F1 jetzt PowerE/scripts/F1_Analyse_Kompensationsforderungen/ ist\n",
    "if SCRIPT_DIR_F1.name == \"F1_Analyse_Kompensationsforderungen\" and SCRIPT_DIR_F1.parent.name == \"scripts\":\n",
    "    PROJECT_ROOT_NB = SCRIPT_DIR_F1.parent.parent\n",
    "else:\n",
    "    # Fallback, falls die Ordnerstruktur anders ist oder das Notebook woanders gestartet wird\n",
    "    PROJECT_ROOT_NB = Path(os.getcwd()).resolve() # Nimm CWD als Projekt-Root\n",
    "    if PROJECT_ROOT_NB.name == \"F1_Analyse_Kompensationsforderungen\": PROJECT_ROOT_NB = PROJECT_ROOT_NB.parent.parent\n",
    "    elif PROJECT_ROOT_NB.name == \"scripts\": PROJECT_ROOT_NB = PROJECT_ROOT_NB.parent\n",
    "    print(f\"WARNUNG: Projekt-Root-Bestimmung ist möglicherweise ungenau. PROJECT_ROOT_NB gesetzt auf: {PROJECT_ROOT_NB}\")\n",
    "    print(\"Stelle sicher, dass dies dein 'PowerE'-Verzeichnis ist.\")\n",
    "\n",
    "\n",
    "if str(PROJECT_ROOT_NB) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_NB))\n",
    "    print(f\"Added project root '{PROJECT_ROOT_NB}' to sys.path\")\n",
    "\n",
    "print(f\"Verwendeter Projekt-Root für dieses Notebook: {PROJECT_ROOT_NB}\")\n",
    "\n",
    "# --- Importe deiner Module ---\n",
    "try:\n",
    "    from src.logic.respondent_level_model.data_transformer import create_respondent_flexibility_df\n",
    "    from src.data_loader.survey_loader.demographics import load_demographics\n",
    "    from src.data_loader.survey_loader.attitudes import load_attitudes\n",
    "    from src.data_loader.survey_loader.demand_response import load_importance, load_notification, load_smart_plug\n",
    "    from src.data_loader.survey_loader.socioeconomics import load_socioeconomics\n",
    "    print(\"Alle benötigten Module aus 'src' erfolgreich importiert.\")\n",
    "except ImportError as e:\n",
    "    print(f\"FEHLER beim Importieren von Modulen aus 'src': {e}\")\n",
    "    print(\"Bitte stelle sicher, dass der PROJECT_ROOT_NB korrekt ist und alle __init__.py Dateien in src und Unterordnern vorhanden sind.\")\n",
    "    raise e\n",
    "except Exception as e:\n",
    "    print(f\"Ein unerwarteter Fehler beim Importieren ist aufgetreten: {e}\")\n",
    "    raise e\n",
    "\n",
    "# --- Lade df_respondent_flexibility (Q9 & Q10 kombiniert) ---\n",
    "print(\"\\nLade df_respondent_flexibility (Q9 & Q10 kombiniert)...\")\n",
    "try:\n",
    "    df_flex = create_respondent_flexibility_df() # Diese Funktion sollte jetzt ohne Argument funktionieren,\n",
    "                                                 # da ihre internen Loader ihre Pfade selbst korrekt finden.\n",
    "    print(f\"df_flexibility geladen. Shape: {df_flex.shape}\")\n",
    "    if df_flex.empty:\n",
    "        print(\"WARNUNG: df_flexibility ist leer! Die weitere Analyse wird nicht aussagekräftig sein.\")\n",
    "    else:\n",
    "        if 'respondent_id' in df_flex.columns:\n",
    "            df_flex['respondent_id'] = df_flex['respondent_id'].astype(str)\n",
    "        print(\"Erste Zeilen von df_flexibility:\")\n",
    "        display(df_flex.head()) # display() ist besser für DataFrames in Jupyter\n",
    "        print(\"\\nInfo zu df_flexibility:\")\n",
    "        df_flex.info()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FEHLER beim Erstellen von df_flexibility (zugrundeliegende Q9/Q10 CSVs nicht gefunden?): {e}\")\n",
    "    df_flex = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"Ein anderer Fehler beim Erstellen von df_flexibility: {e}\")\n",
    "    df_flex = pd.DataFrame()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 2: Laden und Integration weiterer relevanter Umfragedaten\n",
    "# Hier laden wir die soziodemografischen Daten sowie Antworten zu anderen relevanten Fragen und führen sie mit `df_flex` zusammen, um unseren `master_df_f1` zu erstellen.\n",
    "\n",
    "# %% [code]\n",
    "master_df = pd.DataFrame()\n",
    "if not df_flex.empty:\n",
    "    master_df = df_flex.copy()\n",
    "\n",
    "    data_loader_functions = {\n",
    "        \"demographics\": (load_demographics, None), # Key in dict, loader_func, optional sub_key_in_dict_from_loader\n",
    "        \"socioeconomics\": (load_socioeconomics, None),\n",
    "        \"attitudes\": (load_attitudes, None),\n",
    "        \"q8_importance\": (load_importance, \"importance\"), # load_importance gibt direkt DF zurück\n",
    "        \"q11_notification\": (load_notification, \"notification\"),\n",
    "        \"q12_smartplug\": (load_smart_plug, \"smart_plug\")\n",
    "    }\n",
    "\n",
    "    for group_key, (loader_func, specific_df_key) in data_loader_functions.items():\n",
    "        print(f\"\\nLade und merge Daten für: {group_key}...\")\n",
    "        try:\n",
    "            # Übergebe PROJECT_ROOT_NB an die Loader-Funktionen\n",
    "            loaded_data = loader_func(PROJECT_ROOT_NB)\n",
    "            \n",
    "            if isinstance(loaded_data, dict): # Für Loader, die ein Dict von DFs zurückgeben (demographics, socioeconomics, attitudes)\n",
    "                for sub_key, df_to_merge in loaded_data.items():\n",
    "                    print(f\"  Merging Untergruppe: {sub_key} (Shape: {df_to_merge.shape if not df_to_merge.empty else 'leer'})\")\n",
    "                    if not df_to_merge.empty and 'respondent_id' in df_to_merge.columns:\n",
    "                        df_to_merge['respondent_id'] = df_to_merge['respondent_id'].astype(str)\n",
    "                        master_df = pd.merge(master_df, df_to_merge, on=\"respondent_id\", how=\"left\", suffixes=('', f'_{sub_key}_dup'))\n",
    "                    else:\n",
    "                        print(f\"    WARNUNG: DataFrame für '{sub_key}' aus '{group_key}' ist leer oder hat keine 'respondent_id'.\")\n",
    "            elif isinstance(loaded_data, pd.DataFrame): # Für Loader, die direkt einen DataFrame zurückgeben (Q8, Q11, Q12)\n",
    "                df_to_merge = loaded_data\n",
    "                print(f\"  Merging: {group_key} (Shape: {df_to_merge.shape if not df_to_merge.empty else 'leer'})\")\n",
    "                if not df_to_merge.empty and 'respondent_id' in df_to_merge.columns:\n",
    "                    df_to_merge['respondent_id'] = df_to_merge['respondent_id'].astype(str)\n",
    "                    if group_key == \"q8_importance\": # Spezifische Behandlung für Q8 (wide format)\n",
    "                        device_cols_q8 = [col for col in df_to_merge.columns if col != 'respondent_id']\n",
    "                        if device_cols_q8:\n",
    "                            df_q8_long = df_to_merge.melt(id_vars=['respondent_id'], value_vars=device_cols_q8,\n",
    "                                                        var_name='device', value_name='importance_rating')\n",
    "                            # Wichtig: 'device' Spaltennamen müssen exakt übereinstimmen mit master_df['device']\n",
    "                            # Ggf. hier Mapping einfügen, wenn die Namen nicht direkt matchen\n",
    "                            master_df = pd.merge(master_df, df_q8_long, on=[\"respondent_id\", \"device\"], how=\"left\")\n",
    "                        else:\n",
    "                             print(f\"    WARNUNG: Keine Geräte-Spalten in '{group_key}' für melt-Operation gefunden.\")\n",
    "                    else: # Für Q11, Q12\n",
    "                        master_df = pd.merge(master_df, df_to_merge, on=\"respondent_id\", how=\"left\", suffixes=('', f'_{group_key}_dup'))\n",
    "                else:\n",
    "                    print(f\"    WARNUNG: DataFrame für '{group_key}' ist leer oder hat keine 'respondent_id'.\")\n",
    "            else:\n",
    "                print(f\"    WARNUNG: Unerwarteter Rückgabetyp von loader_func für '{group_key}'.\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"    FEHLER: Mindestens eine Datei für '{group_key}' nicht gefunden: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Ein anderer Fehler beim Laden/Mergen von '{group_key}': {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "    print(\"\\n--- Master DataFrame (master_df_f1) nach Merging (Auszug) ---\")\n",
    "    if not master_df.empty:\n",
    "        # Umbenennen des master_df für Klarheit im weiteren Verlauf des Notebooks\n",
    "        master_df_f1 = master_df.copy() \n",
    "        del master_df # Aufräumen\n",
    "        print(\"Erste 5 Zeilen von master_df_f1:\")\n",
    "        display(master_df_f1.head())\n",
    "        print(\"\\nInfo zu master_df_f1:\")\n",
    "        master_df_f1.info(verbose=True, show_counts=True)\n",
    "        print(f\"\\nAnzahl unique Respondent IDs im master_df_f1: {master_df_f1['respondent_id'].nunique()}\")\n",
    "        print(f\"Anzahl Zeilen im master_df_f1: {len(master_df_f1)}\")\n",
    "        \n",
    "        # Überprüfe, ob die kritischen Spalten jetzt vorhanden sind\n",
    "        print(\"\\nÜberprüfung kritischer Spalten im master_df_f1:\")\n",
    "        critical_cols_for_f1 = ['device', 'max_duration_hours', 'incentive_choice', 'incentive_pct_required',\n",
    "                                'age', 'gender', 'household_size', 'accommodation', 'electricity', # aus demographics\n",
    "                                'q13_income', 'q14_education', 'q15_party', # aus socioeconomics\n",
    "                                'importance_rating', # aus q8\n",
    "                                'q11_notify', # aus q11\n",
    "                                'q12_smartplug' # aus q12\n",
    "                               ]\n",
    "        for col in critical_cols_for_f1:\n",
    "            if col in master_df_f1.columns:\n",
    "                print(f\"  Spalte '{col}': Vorhanden, Nicht-Null: {master_df_f1[col].notna().sum()}, Dtype: {master_df_f1[col].dtype}\")\n",
    "            else:\n",
    "                print(f\"  FEHLER: Spalte '{col}' fehlt im master_df_f1!\")\n",
    "    else:\n",
    "        print(\"master_df ist leer. Überprüfe die Datenladeprozesse.\")\n",
    "        master_df_f1 = pd.DataFrame() # Sicherstellen, dass es existiert, auch wenn leer\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 3: Deskriptive Analyse der Teilnahmebereitschaft (Q10 `incentive_choice`)\n",
    "# Wie ist die generelle Bereitschaft zur Teilnahme an DR-Programmen?\n",
    "# - Freiwillig (`yes_fixed`)\n",
    "# - Nur mit Kompensation (`yes_conditional`)\n",
    "# - Gar nicht (`no`)\n",
    "#\n",
    "# Analysiert gesamt, pro Gerät, und pro Dauer.\n",
    "\n",
    "# %% [code]\n",
    "if not master_df_f1.empty and 'incentive_choice' in master_df_f1.columns and 'device' in master_df_f1.columns:\n",
    "    print(\"\\n--- Verteilung der Teilnahmebereitschaft (incentive_choice) ---\")\n",
    "    \n",
    "    # Gesamtverteilung\n",
    "    print(\"\\nGesamtverteilung der Teilnahmebereitschaft (Q10):\")\n",
    "    overall_participation_choice = master_df_f1['incentive_choice'].value_counts(normalize=True).mul(100).round(1)\n",
    "    display(overall_participation_choice.to_frame(name=\"Anteil (%)\"))\n",
    "    fig_overall_choice = px.bar(overall_participation_choice.reset_index(), \n",
    "                                x='incentive_choice', y='proportion', # 'proportion' ist der neue Name von value_counts\n",
    "                                title='Gesamte Teilnahmebereitschaft (Q10)', \n",
    "                                labels={'proportion':'Anteil (%)', 'incentive_choice': 'Teilnahme-Typ (Q10)'},\n",
    "                                text_auto=True)\n",
    "    fig_overall_choice.update_traces(texttemplate='%{y:.1f}%', textposition='outside')\n",
    "    fig_overall_choice.show()\n",
    "\n",
    "    # Pro Gerät\n",
    "    print(\"\\nTeilnahmebereitschaft (Q10) pro Gerät:\")\n",
    "    participation_by_device = master_df_f1.groupby('device')['incentive_choice'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "    display(participation_by_device.pivot(index='device', columns='incentive_choice', values='percentage').fillna(0).round(1))\n",
    "    fig_device_choice = px.bar(participation_by_device, x='device', y='percentage', color='incentive_choice',\n",
    "                               barmode='group', title='Teilnahmebereitschaft pro Gerät (Q10)',\n",
    "                               labels={'percentage':'Anteil (%)', 'device':'Gerät', 'incentive_choice':'Teilnahme-Typ (Q10)'},\n",
    "                               text_auto=True)\n",
    "    fig_device_choice.update_traces(texttemplate='%{y:.1f}%', textposition='outside')\n",
    "    fig_device_choice.update_xaxes(categoryorder='total descending') # Sortiere Geräte nach Gesamtanteil\n",
    "    fig_device_choice.show()\n",
    "\n",
    "    # Pro Dauer (max_duration_hours aus Q9)\n",
    "    if 'max_duration_hours' in master_df_f1.columns:\n",
    "        print(\"\\nTeilnahmebereitschaft (Q10) pro angegebener max. Nichtnutzungsdauer (Q9):\")\n",
    "        master_df_f1['max_duration_hours_num'] = pd.to_numeric(master_df_f1['max_duration_hours'], errors='coerce')\n",
    "        \n",
    "        participation_by_duration = master_df_f1.dropna(subset=['max_duration_hours_num']).groupby('max_duration_hours_num')['incentive_choice'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "        display(participation_by_duration.pivot(index='max_duration_hours_num', columns='incentive_choice', values='percentage').fillna(0).round(1))\n",
    "        fig_duration_choice = px.bar(participation_by_duration, x='max_duration_hours_num', y='percentage', color='incentive_choice',\n",
    "                                     barmode='group', title='Teilnahmebereitschaft (Q10) nach max. Nichtnutzungsdauer (Q9)',\n",
    "                                     labels={'percentage':'Anteil (%)', 'max_duration_hours_num':'Max. Nichtnutzungsdauer (Stunden, Q9)', 'incentive_choice':'Teilnahme-Typ (Q10)'},\n",
    "                                     text_auto=True)\n",
    "        fig_duration_choice.update_traces(texttemplate='%{y:.1f}%', textposition='outside')\n",
    "        fig_duration_choice.show()\n",
    "else:\n",
    "    print(\"master_df_f1 ist leer oder notwendige Spalten ('incentive_choice', 'device') fehlen für Abschnitt 3.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 4: Detaillierte Analyse der monetären Kompensationsforderungen (Q10 `incentive_pct_required`)\n",
    "# Für diejenigen, die eine Kompensation fordern (`incentive_choice == 'yes_conditional'`):\n",
    "# - Wie hoch sind die Forderungen in Prozent?\n",
    "# - Gibt es Unterschiede pro Gerät und pro Dauer?\n",
    "\n",
    "# %% [code]\n",
    "if not master_df_f1.empty and 'incentive_choice' in master_df_f1.columns and 'incentive_pct_required' in master_df_f1.columns:\n",
    "    print(\"\\n--- Analyse der monetären Kompensationsforderungen (incentive_pct_required) ---\")\n",
    "    df_compens_demand = master_df_f1[master_df_f1['incentive_choice'] == 'yes_conditional'].copy()\n",
    "    \n",
    "    df_compens_demand['incentive_pct_required_num'] = pd.to_numeric(df_compens_demand['incentive_pct_required'], errors='coerce')\n",
    "    df_compens_demand.dropna(subset=['incentive_pct_required_num'], inplace=True)\n",
    "\n",
    "    if not df_compens_demand.empty:\n",
    "        print(\"\\nDeskriptive Statistik für Kompensationsforderung (gesamt, für 'yes_conditional'):\")\n",
    "        display(df_compens_demand['incentive_pct_required_num'].describe().round(2).to_frame())\n",
    "\n",
    "        fig_hist_total_compens = px.histogram(df_compens_demand, x='incentive_pct_required_num', nbins=20,\n",
    "                                              title=\"Gesamtverteilung der geforderten Kompensation (%) für 'yes_conditional'\",\n",
    "                                              labels={'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "        fig_hist_total_compens.show()\n",
    "\n",
    "        print(\"\\n--- Kompensationsforderungen pro Gerät (für 'yes_conditional') ---\")\n",
    "        for device_name in sorted(df_compens_demand['device'].unique()):\n",
    "            print(f\"\\nKompensationsforderung für: {device_name}\")\n",
    "            device_subset = df_compens_demand[df_compens_demand['device'] == device_name]\n",
    "            if not device_subset.empty:\n",
    "                display(device_subset['incentive_pct_required_num'].describe().round(2).to_frame())\n",
    "                fig_hist_device = px.histogram(device_subset, x='incentive_pct_required_num', nbins=10,\n",
    "                                               title=f\"Verteilung Kompensation (%) für {device_name}\",\n",
    "                                               labels={'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "                fig_hist_device.show()\n",
    "\n",
    "                if 'max_duration_hours_num' in device_subset.columns: # max_duration_hours_num wurde in Abschnitt 3 erstellt\n",
    "                    fig_box_device_duration = px.box(device_subset.dropna(subset=['max_duration_hours_num']), \n",
    "                                                     x='max_duration_hours_num', y='incentive_pct_required_num',\n",
    "                                                     title=f\"Kompensation vs. Max. Dauer für {device_name}\",\n",
    "                                                     labels={'max_duration_hours_num': 'Max. Nichtnutzungsdauer (Stunden, Q9)', \n",
    "                                                             'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "                    fig_box_device_duration.show()\n",
    "            else:\n",
    "                print(f\"Keine Daten für Kompensationsforderungen für {device_name} gefunden.\")\n",
    "    else:\n",
    "        print(\"Keine Daten für 'yes_conditional' Teilnehmer mit validen Kompensationsforderungen gefunden.\")\n",
    "else:\n",
    "    print(\"master_df_f1 ist leer oder notwendige Spalten fehlen für Abschnitt 4.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 5: Einfluss ausgewählter soziodemografischer Faktoren auf Kompensationsforderungen\n",
    "# Unterscheiden sich die Kompensationsforderungen (`incentive_pct_required_num` für `yes_conditional`) basierend auf z.B. Einkommen oder Alter?\n",
    "\n",
    "# %% [code]\n",
    "# Stelle sicher, dass df_compens_demand aus Abschnitt 4 existiert und nicht leer ist\n",
    "if 'df_compens_demand' in locals() and not df_compens_demand.empty:\n",
    "    print(\"\\n--- Analyse des Einflusses soziodemografischer Faktoren auf Kompensationsforderungen ---\")\n",
    "    \n",
    "    # Einkommen (q13_income)\n",
    "    if 'q13_income' in df_compens_demand.columns:\n",
    "        print(\"\\nKompensationsforderung nach Einkommen:\")\n",
    "        income_categories_order = [\n",
    "            \"Unter 3.000 CHF\", \"3.000 - 5.000 CHF\", \"5.001 - 7.000 CHF\",\n",
    "            \"7.001 - 10.000 CHF\", \"Über 10.000 CHF\", \"Keine Angabe\"\n",
    "        ]\n",
    "        df_compens_demand['q13_income_cat'] = pd.Categorical(\n",
    "            df_compens_demand['q13_income'], categories=income_categories_order, ordered=True\n",
    "        )\n",
    "        \n",
    "        fig_income_compens = px.box(df_compens_demand.dropna(subset=['q13_income_cat', 'incentive_pct_required_num']),\n",
    "                                     x='q13_income_cat', y='incentive_pct_required_num',\n",
    "                                     title='Kompensationsforderung nach Haushaltseinkommen',\n",
    "                                     labels={'q13_income_cat': 'Monatl. Haushaltsnettoeinkommen (Q13)',\n",
    "                                             'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "        fig_income_compens.update_xaxes(tickangle=30)\n",
    "        fig_income_compens.show()\n",
    "        display(df_compens_demand.groupby('q13_income_cat', observed=False)['incentive_pct_required_num'].agg(['mean', 'median', 'std', 'count']).round(2))\n",
    "    else:\n",
    "        print(\"Spalte 'q13_income' nicht im DataFrame für Kompensationsforderungen gefunden.\")\n",
    "\n",
    "    # Alter (age) - 'age' Spalte sollte numerisch sein aus Abschnitt 2\n",
    "    if 'age' in df_compens_demand.columns:\n",
    "        print(\"\\nKompensationsforderung nach Alter:\")\n",
    "        # Altersgruppen bilden\n",
    "        age_bins = [0, 25, 35, 45, 55, 65, 120] # Beispiel-Bins, anpassen!\n",
    "        age_labels = [\"<25\", \"25-35\", \"36-45\", \"46-55\", \"56-65\", \"65+\"]\n",
    "        df_compens_demand['age_group'] = pd.cut(df_compens_demand['age'], bins=age_bins, labels=age_labels, right=True, include_lowest=True)\n",
    "        \n",
    "        fig_age_compens = px.box(df_compens_demand.dropna(subset=['age_group', 'incentive_pct_required_num']),\n",
    "                                 x='age_group', y='incentive_pct_required_num',\n",
    "                                 title='Kompensationsforderung nach Altersgruppe (Q1)',\n",
    "                                 labels={'age_group': 'Altersgruppe',\n",
    "                                         'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "        fig_age_compens.show()\n",
    "        display(df_compens_demand.groupby('age_group', observed=False)['incentive_pct_required_num'].agg(['mean', 'median', 'std', 'count']).round(2))\n",
    "    else:\n",
    "        print(\"Spalte 'age' nicht im DataFrame für Kompensationsforderungen gefunden.\")\n",
    "        \n",
    "    # Hier weitere Analysen für Bildung (q14_education), Haushaltsgröße (household_size) etc. analog hinzufügen.\n",
    "    # Beispiel für Bildung:\n",
    "    if 'q14_education' in df_compens_demand.columns:\n",
    "        print(\"\\nKompensationsforderung nach Bildung:\")\n",
    "        # Bildung kategorien (anpassen an deine Daten!)\n",
    "        # education_order = [\"Grundschule\", \"Sekundarschule/Realschule\", \"Berufsausbildung/Lehre/Maturität\", \"Fachhochschule/Bachelor\", \"Universität/Master\", \"Promotion oder höher\", \"Keine Schulbildung\", \"Keine Angabe\"]\n",
    "        # df_compens_demand['q14_education_cat'] = pd.Categorical(df_compens_demand['q14_education'], categories=education_order, ordered=True)\n",
    "        \n",
    "        fig_edu_compens = px.box(df_compens_demand.dropna(subset=['q14_education', 'incentive_pct_required_num']),\n",
    "                                     x='q14_education', y='incentive_pct_required_num',\n",
    "                                     title='Kompensationsforderung nach höchstem Bildungsabschluss (Q14)',\n",
    "                                     labels={'q14_education': 'Bildungsabschluss',\n",
    "                                             'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "        fig_edu_compens.update_xaxes(tickangle=30)\n",
    "        fig_edu_compens.show()\n",
    "        display(df_compens_demand.groupby('q14_education')['incentive_pct_required_num'].agg(['mean', 'median', 'std', 'count']).round(2))\n",
    "    else:\n",
    "        print(\"Spalte 'q14_education' nicht im DataFrame für Kompensationsforderungen gefunden.\")\n",
    "else:\n",
    "    print(\"df_compens_demand ist leer oder nicht definiert, keine soziodemografische Analyse möglich.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 6 (Optional): Einfluss von Geräte-Wichtigkeit (Q8) und DR-Affinität (Q11, Q12)\n",
    "\n",
    "# %% [code]\n",
    "if 'df_compens_demand' in locals() and not df_compens_demand.empty:\n",
    "    print(\"\\n--- Analyse zusätzlicher Einflussfaktoren (Optional) ---\")\n",
    "\n",
    "    # Q8 - Wichtigkeit des Geräts\n",
    "    # 'importance_rating' sollte im master_df_f1 (und somit in df_compens_demand) sein,\n",
    "    # wenn der Merge in Abschnitt 2 für Q8 (melted) erfolgreich war.\n",
    "    if 'importance_rating' in df_compens_demand.columns:\n",
    "        print(\"\\nKompensationsforderung nach Wichtigkeit des Geräts (Q8):\")\n",
    "        # Stelle sicher, dass importance_rating numerisch ist\n",
    "        df_compens_demand['importance_rating_num'] = pd.to_numeric(df_compens_demand['importance_rating'], errors='coerce')\n",
    "        \n",
    "        fig_importance = px.box(df_compens_demand.dropna(subset=['importance_rating_num', 'incentive_pct_required_num']),\n",
    "                                 x='importance_rating_num', y='incentive_pct_required_num',\n",
    "                                 title='Kompensationsforderung vs. Wichtigkeit des Geräts (Q8)',\n",
    "                                 labels={'importance_rating_num': 'Wichtigkeit (1=sehr unwichtig, 5=sehr wichtig)',\n",
    "                                         'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "        fig_importance.show()\n",
    "        display(df_compens_demand.groupby('importance_rating_num')['incentive_pct_required_num'].agg(['mean', 'median', 'std', 'count']).round(2))\n",
    "    else:\n",
    "        print(\"Spalte 'importance_rating' (aus Q8) nicht im DataFrame gefunden. Überprüfe den Merge-Schritt für Q8 in Abschnitt 2.\")\n",
    "\n",
    "    # Q11 - Benachrichtigungsbereitschaft & Q12 - Smart Plug Akzeptanz\n",
    "    for col_q_akzeptanz, title_akzeptanz in [('q11_notify', 'Benachrichtigungsbereitschaft (Q11)'), \n",
    "                                            ('q12_smartplug', 'Smart Plug Akzeptanz (Q12)')]:\n",
    "        if col_q_akzeptanz in df_compens_demand.columns:\n",
    "            print(f\"\\nKompensationsforderung nach {title_akzeptanz}:\")\n",
    "            # Standardisiere Ja/Nein Antworten, falls nötig (z.B. \"Ja \", \"ja\" -> \"Ja\")\n",
    "            # Deine Preprocessing-Skripte sollten das schon erledigen (str.capitalize())\n",
    "            # df_compens_demand[col_q_akzeptanz] = df_compens_demand[col_q_akzeptanz].str.strip().str.capitalize()\n",
    "            \n",
    "            fig_q_akzeptanz = px.box(df_compens_demand.dropna(subset=[col_q_akzeptanz, 'incentive_pct_required_num']),\n",
    "                                     x=col_q_akzeptanz, y='incentive_pct_required_num',\n",
    "                                     title=f'Kompensationsforderung vs. {title_akzeptanz}',\n",
    "                                     labels={col_q_akzeptanz: title_akzeptanz.split('(')[0].strip(), # Kürzerer Labeltext\n",
    "                                             'incentive_pct_required_num': 'Geforderte Kompensation (%)'})\n",
    "            fig_q_akzeptanz.show()\n",
    "            display(df_compens_demand.groupby(col_q_akzeptanz)['incentive_pct_required_num'].agg(['mean', 'median', 'std', 'count']).round(2))\n",
    "        else:\n",
    "            print(f\"Spalte '{col_q_akzeptanz}' nicht im DataFrame gefunden.\")\n",
    "else:\n",
    "    print(\"df_compens_demand ist leer oder nicht definiert, keine Analyse zusätzlicher Einflussfaktoren möglich.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Abschnitt 7: Zusammenfassung der Kernergebnisse für F1 und Export\n",
    "#\n",
    "# *Hier fasst du die wichtigsten Erkenntnisse in Textform zusammen, basierend auf den obigen Analysen.*\n",
    "# *Beispiel:*\n",
    "# * \"Die Analyse der Umfragedaten von XYZ Schweizer Haushalten zeigt, dass die Bereitschaft zur Teilnahme an Peak-Shaving-Programmen stark von den angebotenen Anreizen abhängt. Im Median fordern die teilnahmebereiten Haushalte eine Kompensation von 15% der Stromkosten für eine Verschiebung.\"\n",
    "# * \"Für das Gerät 'Waschmaschine' liegt die mittlere Kompensationsforderung bei A%, während für 'Geschirrspüler' B% gefordert werden. Dies deutet auf eine unterschiedliche Wertschätzung der ununterbrochenen Verfügbarkeit hin.\"\n",
    "# * \"Haushalte mit einem Nettoeinkommen über 10.000 CHF zeigen tendenziell [höhere/niedrigere/ähnliche] Kompensationsforderungen (Median C%) im Vergleich zu Haushalten mit einem Einkommen unter 3.000 CHF (Median D%).\"\n",
    "#\n",
    "# *Code zum Speichern wichtiger Tabellen und Grafiken:*\n",
    "\n",
    "# %% [code]\n",
    "# Erstelle den outputs-Ordner, falls er nicht existiert\n",
    "output_dir_f1 = PROJECT_ROOT_NB / \"scripts\" / \"F1_Analyse_Kompensationsforderungen\" / \"outputs\"\n",
    "os.makedirs(output_dir_f1, exist_ok=True)\n",
    "print(f\"Ausgaben werden in '{output_dir_f1}' gespeichert.\")\n",
    "\n",
    "# Beispiel: Speichere deskriptive Statistiken der Kompensationsforderungen pro Gerät\n",
    "if 'df_compens_demand' in locals() and not df_compens_demand.empty:\n",
    "    try:\n",
    "        stats_compens_per_device = df_compens_demand.groupby('device')['incentive_pct_required_num'].describe().round(2)\n",
    "        stats_compens_per_device_path = output_dir_f1 / \"f1_tabelle_kompensation_pro_geraet.csv\"\n",
    "        stats_compens_per_device.to_csv(stats_compens_per_device_path)\n",
    "        print(f\"Tabelle 'kompensation_pro_geraet.csv' gespeichert.\")\n",
    "\n",
    "        # Beispiel: Speichere einen der erstellten Plots (z.B. den Gesamt-Histogramm der Kompensation)\n",
    "        # Dazu muss die Figur einer Variablen zugewiesen worden sein, z.B. fig_hist_total_compens\n",
    "        if 'fig_hist_total_compens' in locals():\n",
    "            fig_hist_total_compens.write_html(output_dir_f1 / \"f1_plot_gesamte_kompensationsverteilung.html\")\n",
    "            # Für PNG: fig_hist_total_compens.write_image(output_dir_f1 / \"f1_plot_gesamte_kompensationsverteilung.png\") # Benötigt kaleido\n",
    "            print(f\"Plot 'gesamte_kompensationsverteilung.html' gespeichert.\")\n",
    "        \n",
    "        # Du müsstest die anderen Plotly Express Figuren (px.) ebenfalls Variablen zuweisen, um sie zu speichern:\n",
    "        # z.B. fig = px.bar(...) dann fig.write_html(...)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Speichern der Ergebnisse: {e}\")\n",
    "else:\n",
    "    print(\"Keine Daten in df_compens_demand zum Speichern vorhanden.\")\n",
    "\n",
    "# %% [code]\n",
    "print(\"\\n--- F1 Analyse Notebook Ende ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
